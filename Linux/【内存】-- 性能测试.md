### 概述

本文先了解下内存架构的演进，然后指出内存主要的性能指标，最后通过工具去演示如何测试内存的性能。

---

### 内存架构

#### UMA (均匀内存访问)

早期的多核 CPU 和内存一般都采用 UMA 架构，每个核通过 FSB (前端系统总线) 与 MCH (主板上的内存控制器) 相连，MCH 再与内存相连。UMA 架构下每个核对内存的访问延迟并没有差距。如下图：

![](https://raw.githubusercontent.com/hsxhr-10/picture/master/内存uma.png)

#### NUMA (非均匀内存访问)

但是随着核数的越来越多的发展趋势下，FSB 和 MCH 成为了 CPU 访问内存的性能瓶颈。这也催生了 NUMA 架构的诞生，NUMA 和 UMA 最大的不同是去掉了 FSB，且 MCH 被集成到了每个核内部。如下图：

![](https://raw.githubusercontent.com/hsxhr-10/picture/master/内存numa.png)

#### 服务器内存架构实物

![](https://raw.githubusercontent.com/hsxhr-10/picture/master/服务器内存实物.png)

---

### 性能指标

- 吞吐量 (throughput)：即内存每秒能传输的字节数
- 访问延迟 (latency)：访问一次内存所需的时间
  - 当内存访问命中 cache 时，访存延迟通常是 ns 级别的
  - 若内存访问引起操作系统的 page fault，访存延迟对应用来说就推迟到了 us ，甚至百 us 级别
  - 若内存访问时的 page fault 遭遇了物理内存紧张，引发了操作系统的页回收，访存延迟可以推迟到 ms 级，一些极端情况可以是百 ms 级，直至 s 级

---

### 测试工具

- mbw：粗略测试内存吞吐量
- pmbw：测试内存吞吐量、延迟，生成直观的 pdf 报表报告

---

### 测试环境

```
# uname -a
Linux ubuntu 3.16.0-30-generic #40~14.04.1-Ubuntu SMP Thu Jan 15 17:43:14 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

# cat /etc/*-release
DISTRIB_DESCRIPTION="Ubuntu 14.04.2 LTS"

# 2G 内存
# CPU：2核
```

---

### 测试演示

#### mbw 演示

```
root@120:/opt/pmbw/pmbw-0.6.2# mbw -n 250 -t 0 350
Long uses 8 bytes. Allocating 2*26214400 elements = 419430400 bytes of memory.
Getting down to business... Doing 250 runs per test.
0	Method: MEMCPY	Elapsed: 0.03813	MiB: 200.00000	Copy: 5245.764 MiB/s
1	Method: MEMCPY	Elapsed: 0.04210	MiB: 200.00000	Copy: 4750.594 MiB/s
2	Method: MEMCPY	Elapsed: 0.04123	MiB: 200.00000	Copy: 4850.719 MiB/s
...
AVG	Method: MEMCPY	Elapsed: 0.11077	MiB: 350.00000	Copy: 3159.739 MiB/s
```

mbw 是通过向内存复制大数组来测试内存的带宽情况，更偏向于用户空间层面看到的内存带宽。重点看最后一行 `AVG	Method: MEMCPY	Elapsed: 0.06556	MiB: 200.00000	Copy: 3050.723 MiB/s` 可知对于用户空间的程序来说，内存带宽大概 3GB 左右。

#### pmbw 演示

```
root@120:/opt/pmbw/pmbw-0.6.2# nice -n -2 ./pmbw -S 0
Running benchmarks with no upper array size limit.
CPUID: mmx sse avx
Detected 990 MiB physical RAM and 2 CPUs. 

Allocating 512 MiB for testing.
Running nthreads=1 factor=1073741824 areasize=1024 thrsize=1152 testsize=1152 repeats=932068 testvol=1073742336 testaccess=134217792
run time = 0.0540974 -> rerunning test with repeat factor=29772499980
Running nthreads=1 factor=29772499980 areasize=1024 thrsize=1152 testsize=1152 repeats=25844185 testvol=29772501120 testaccess=3721562640
run time = 1.48173 -> next test with repeat factor=30139517885
RESULT	datetime=2018-06-13 20:38:41	host=120.78.66.191	version=0.6.2	funcname=ScanWrite64PtrSimpleLoop	nthreads=1	areasize=1024	threadsize=1152	testsize=1152	repeats=25844185	testvol=29772501120	testaccess=3721562640	time=1.4817341089947149158	bandwidth=20093011923.845909119	rate=3.9814837269398073322e-10
Running nthreads=1 factor=30139517885 areasize=2048 thrsize=2176 testsize=2176 repeats=13850882 testvol=30139519232 testaccess=3767439904
...

# 测试时间自行控制，我这次测试了 30 分钟。30 分钟后中断测试

# 生成 pdf 测试报告，没安装 gnuplot 的先通过 apt-get install -y gnuplot 安装
root@120:/opt/pmbw/pmbw-0.6.2# ./stats2gnuplot stats.txt | gnuplot
```

测试报告中有十几幅图，重点看下第 1, 2, 3 副，分别是吞吐量, 混合读写延迟, 顺序读写延迟。如下图：

1. 吞吐量

![](https://raw.githubusercontent.com/hsxhr-10/picture/master/pmbw吞吐量.png)

- ScanRead64PtrUnrollLoop
  - Loop：一个大循环
  - ScanRead：顺序读
  - 64：循环中的数据是 64 位的无符号整型 (uint64_t)
  - Ptr：循环中的操作是指针操作
  - Unroll：循环中有 16 个操作语句
  - 简单理解就是 “多语句的顺序读循环”
```
// ScanRead64PtrUnrollLoop
for (uint64_t* p = array; p < array + an; ++p) {
    uint64_t x0 = *(p+0);
    uint64_t x1 = *(p+1);
    // ... 13 times
    uint64_t x15 = *(p+15);
}
```

- ScanRead64PtrSimpleLoop：单语句的顺序读循环
- ScanWrite64PtrUnrollLoop：多语句的顺序写循环
- ScanWrite64PtrSimpleLoop：单语句的顺序写循环
- 其他的都基本一样，只是带 index 字样的代表循环中的操作是下标操作

可以看到随着操作数组的大小不断增大，读吞吐量趋向 13BG 左右，写吞吐量趋向 8GB 左右。

2. 延迟

第一幅是混合读写访问延迟，第二幅是顺序读写访问延迟。

![](https://raw.githubusercontent.com/hsxhr-10/picture/master/pmbw延迟.png)

![](https://raw.githubusercontent.com/hsxhr-10/picture/master/pmbw延迟顺序读写.png)

可以看到随着操作数组的大小不断增大，读延迟趋向 0.6ns 左右，写延迟趋向 0.8ns 左右。且顺序读写和随机读写之间的延迟基本一致。

> pmbw 相比 mbw 更倾向于硬件本身的性能。关于 pbmw 更详细的信息可以参考 [官方文档](https://panthema.net/2013/pmbw/)

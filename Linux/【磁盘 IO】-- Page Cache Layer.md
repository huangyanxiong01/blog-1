![](https://raw.githubusercontent.com/hsxhr-10/picture/master/Page%20Cache%20Layer.png)

---

### 概述

在日常维护服务器时，使用 `free` 命令会发现 free 字段会随着运行的时间增加而不断变小，而 cache 字段会随着运行的时间增加而不断变大。

```
root@ubuntu:/proc/sys/vm# free -m
             total       used       free     shared    buffers     cached
Mem:           990        872        117          0        155        531
-/+ buffers/cache:        185        805
Swap:            0          0          0
```

这其实是因为 Page Cache 机制导致的。简单来说，如果没有该机制，上层发出的 I/O 请求就会直接落到磁盘设备上，这对于磁盘这种慢设备来说简直是灾难。正是因为有 Page Cache 的存在，大量的 I/O 请求可以在到达 Page Cache Layer 之后就能返回，而无需真正请求磁盘。

---

### 地位和作用

当进程第一次读取某个数据块时，只能直接从磁盘读取，然后内核会向 Page Cache Layer 申请适当的页来缓存读取到的数据块，当有进程需要再次读取之前的数据块时，就会调用 read() 函数，此时 read() 函数通过虚拟内存机制访问到 Page Cache Layer 中缓存好的页，也就避免了对磁盘的 I/O 操作了。Page Cache Layer 即是磁盘子系统的一部分，也是联系内存子系统和磁盘子系统的枢纽，Page Cache Layer 存在于物理内存中，因此既需要和虚拟内存机制协作，又需要和下层文件系统协作。

对于进程来说，如果调用 read() 时缓存命中，I/O 请求就会从 Page Cache Layer 中获取到数据并返回给进程；如果调用 write() 时没有指定要直接写磁盘，I/O 请求就会往 Page Cache Layer 的缓冲区中写入数据，等到缓冲区满了之后，再一次性地将数据写入磁盘。可以看到，Page Cache Layer 让高速的内存暂时替代了低速的磁盘 (前提是缓存命中和缓存写模式)，同时还减少了对磁盘实质的 I/O 操作，降低了磁盘的负担，大大滴提升了磁盘子系统的性能。

---

### 预读和回写

Page Cache Layer 有两大主要的功能，预读和回写。

预读依据的原理有两个：1 是局部性原理，也就是将来要访问的数据的地址和最近访问过的数据的地址很可能是相邻的；2 是磁盘的数据经常是以一族连续扇区的形式组织的。预读的具体过程是，在读取基本所需扇区数量之后，额外地多读取几个扇区 (**可以通过内核参数优化**)，然后再返回结果，这种就叫做同步预读。当下一次的 I/O 请求并没有在额外的扇区中命中时，内核就会继续做同步预读，在往后的观察中，如果还是不命中，就会减少预读的扇区数或者关闭预读。但是，当下一次的 I/O 请求在额外的扇区中命中时，内核就会将预读的扇区数扩大一倍，并且将会以异步的方式去读额外的扇区，也就是说这时无需等待额外的扇区读完就能返回。可以看到，如果预读命中的话，磁盘的读取将会变快。

回写则是通过将要写入磁盘的数据暂时存放于内存中，等到满足一定的条件后 (比如**缓冲区满了或者缓冲区的数据被判定为旧数据**) 才一次性地异步写入磁盘。好处很明显，避免了频发的低效磁盘写操作；缺点也同样明显，内存中暂存的数据可能会丢失。

---

总的来说，Page Cache Layer 可以说是对磁盘性能提升最明显的一个层级，同时，最难能可贵的是，预读和回写留给系统管理员的调优方式也很友好，也就是可以通过修改内核参数去进行性能优化。
